{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src import models, data\n",
    "from tqdm.auto import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "mt = models.load_model(\"gptj\", device=device)\n",
    "print(\n",
    "    f\"dtype: {mt.model.dtype}, device: {mt.model.device}, memory: {mt.model.get_memory_footprint()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"The Space Needle is located in the city of\"\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True).to(mt.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import baukit\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    mt.model,\n",
    "    mt.layer_names,\n",
    ") as traces:\n",
    "    output = mt.model(**tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output.logits[0][-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def untuple(x):\n",
    "    if isinstance(x, tuple):\n",
    "        return x[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def interpret_logits(mt, logits, top_k=10):\n",
    "    token_ids = logits.topk(dim=-1, k=top_k).indices.squeeze().tolist()\n",
    "    logit_values = logits.topk(dim=-1, k=top_k).values.squeeze().tolist()\n",
    "    return [\n",
    "        (mt.tokenizer.decode(t), round(v, 3)) for t, v in zip(token_ids, logit_values)\n",
    "    ]\n",
    "\n",
    "\n",
    "def logit_lens(\n",
    "    mt,\n",
    "    h,\n",
    "    interested_tokens=[],\n",
    "    get_proba=False,\n",
    "):\n",
    "    logits = mt.lm_head(h)\n",
    "    logits = torch.nn.functional.softmax(logits, dim=-1) if get_proba else logits\n",
    "    candidates = interpret_logits(mt, logits)\n",
    "    interested_logits = {\n",
    "        t.item(): (logits[t].item(), mt.tokenizer.decode(t)) for t in interested_tokens\n",
    "    }\n",
    "    return candidates, interested_logits\n",
    "\n",
    "\n",
    "# interpret_logits(mt, output.logits[0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interested_words = [\" Seattle\", \" Paris\", \" Dhaka\"]\n",
    "# int_tokenized = mt.tokenizer(interested_words, return_tensors=\"pt\", padding=True).to(\n",
    "#     mt.model.device\n",
    "# )\n",
    "# int_tokenized.input_ids\n",
    "\n",
    "# z = untuple(traces[mt.layer_names[-1]].output)[0][-1]\n",
    "# print(z.shape)\n",
    "\n",
    "# logit_lens(mt, z, [t[0] for t in int_tokenized.input_ids], get_proba=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_by_model_knowledge(mt, relation_prompt, relation_samples):\n",
    "    model_knows = []\n",
    "    for sample in relation_samples:\n",
    "        tokenized = relation_prompt.format(sample.subject)\n",
    "        output = mt.model(\n",
    "            **mt.tokenizer(tokenized, return_tensors=\"pt\", padding=True).to(\n",
    "                mt.model.device\n",
    "            )\n",
    "        )\n",
    "\n",
    "        object_id = output.logits[0][-1].argmax().item()\n",
    "        object = mt.tokenizer.decode(object_id)\n",
    "\n",
    "        tick = sample.object.strip().startswith(object.strip())\n",
    "        # print(object, sample.object, tick)\n",
    "\n",
    "        if tick:\n",
    "            model_knows.append(sample)\n",
    "\n",
    "    return model_knows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.load_dataset()\n",
    "capital_cities = dataset[0]\n",
    "capital_cities.__dict__.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "icl_indices = np.random.choice(range(len(capital_cities.samples)), 3, replace=False)\n",
    "icl_samples = [capital_cities.samples[i] for i in icl_indices]\n",
    "icl_prompt = [\n",
    "    f\"{capital_cities.prompt_templates[0].format(sample.subject)} {sample.object}\"\n",
    "    for sample in icl_samples\n",
    "]\n",
    "icl_prompt = \"\\n\".join(icl_prompt) + \"\\n\" + capital_cities.prompt_templates[0]\n",
    "\n",
    "print(icl_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_knows = filter_by_model_knowledge(mt, icl_prompt, capital_cities.samples)\n",
    "len(model_knows)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Richness based on logit lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_richness(mt, relation_prompt, subject, verbose=False):\n",
    "    tokenized = relation_prompt.format(subject)\n",
    "    with baukit.TraceDict(mt.model, layers=mt.layer_names) as traces:\n",
    "        output = mt.model(\n",
    "            **mt.tokenizer(tokenized, return_tensors=\"pt\", padding=True).to(\n",
    "                mt.model.device\n",
    "            )\n",
    "        )\n",
    "\n",
    "    object_id = output.logits[0][-1].argmax().item()\n",
    "    object = mt.tokenizer.decode(object_id)\n",
    "    # base_logit = output.logits[0][-1][object_id].item()\n",
    "    base_score = torch.nn.functional.softmax(output.logits[0][-1], dim=-1)[\n",
    "        object_id\n",
    "    ].item()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"object ==> {object} [{object_id}], base = {base_score}\")\n",
    "\n",
    "    layer_contributions = {}\n",
    "\n",
    "    prev_score = 0\n",
    "    for layer in mt.layer_names:\n",
    "        h = untuple(traces[layer].output)[0][-1]\n",
    "        candidates, interested_logits = logit_lens(\n",
    "            mt, h, torch.tensor([object_id]), get_proba=True\n",
    "        )\n",
    "        layer_score = interested_logits[object_id][0]\n",
    "        cur_layer_contribution = (layer_score - base_score) / base_score\n",
    "\n",
    "        layer_contributions[layer] = cur_layer_contribution\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"layer: {layer}, diff: {cur_layer_contribution}\")\n",
    "\n",
    "        prev_score = layer_score\n",
    "\n",
    "    return layer_contributions\n",
    "\n",
    "\n",
    "relation_prompt = mt.tokenizer.eos_token + \" {} is located in the city of\"\n",
    "subject = \"The Space Needle\"\n",
    "layer_richness(mt, relation_prompt, subject, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_richness_info = {layer: [] for layer in mt.layer_names}\n",
    "\n",
    "for sample in tqdm(model_knows):\n",
    "    cur_richness = layer_richness(mt, icl_prompt, sample.subject)\n",
    "    for layer in mt.layer_names:\n",
    "        layer_richness_info[layer].append(cur_richness[layer])\n",
    "\n",
    "# with open(\"layer_sweep/layer_contribution_info.json\", \"w\") as f:\n",
    "with open(\"layer_sweep/layer_completeness_info.json\", \"w\") as f:\n",
    "    json.dump(layer_richness_info, f)\n",
    "\n",
    "for layer in mt.layer_names:\n",
    "    layer_richness_info[layer] = np.array(layer_richness_info[layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_richness = [layer_richness_info[layer].mean() for layer in mt.layer_names]\n",
    "low_richness = [layer_richness_info[layer].min() for layer in mt.layer_names]\n",
    "high_richness = [layer_richness_info[layer].max() for layer in mt.layer_names]\n",
    "\n",
    "plt.plot(mean_richness, color=\"blue\")\n",
    "plt.fill_between(range(len(mean_richness)), low_richness, high_richness, alpha=0.2)\n",
    "plt.axhline(0, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "plt.xlabel(\"Layer\")\n",
    "plt.ylabel(\"completeness\")\n",
    "plt.xticks(range(0, len(mean_richness), 2))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer Richness based on `Jh_norm` and `J_norm`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "capital_cities_known = copy.deepcopy(capital_cities.__dict__)\n",
    "capital_cities_known[\"samples\"] = model_knows\n",
    "\n",
    "capital_cities_known = data.Relation(**capital_cities_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import RelationSample\n",
    "RelationSample(subject=\"Russia\", object=\"Moscow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(icl_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import JacobianEstimator, JacobianIclMeanEstimator\n",
    "\n",
    "# mean_estimator = JacobianIclMeanEstimator(\n",
    "#     mt=mt,\n",
    "#     h_layer=12,\n",
    "# )\n",
    "\n",
    "# operator = mean_estimator(capital_cities_subset)\n",
    "# operator(\"Russia\", k = 10).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = JacobianEstimator(\n",
    "    mt=mt,\n",
    "    h_layer=12,\n",
    ")\n",
    "\n",
    "operator = estimator.call_on_sample(\n",
    "    sample = RelationSample(subject=\"Russia\", object=\"Moscow\"),\n",
    "    prompt_template= icl_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator.misc[\"Jh\"].norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_prompt = icl_prompt\n",
    "subject = \"Russia\"\n",
    "layer_richness(mt, relation_prompt, subject, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layerwise_jh = {layer: [] for layer in mt.layer_names}\n",
    "\n",
    "for sample in tqdm(set(model_knows) - set(icl_samples)):\n",
    "    for h_layer in range(0, 24):\n",
    "        layer_name = mt.layer_name_format.format(h_layer)\n",
    "        estimator = JacobianEstimator(\n",
    "            mt=mt,\n",
    "            h_layer=h_layer,\n",
    "        )\n",
    "        operator = estimator.call_on_sample(\n",
    "            # sample = RelationSample(subject=\"Russia\", object=\"Moscow\"),\n",
    "            sample = sample,\n",
    "            prompt_template= icl_prompt\n",
    "        )\n",
    "\n",
    "        # print(h_layer, \" ===> \", f\"J:{operator.weight.norm().item()},  Jh: {operator.misc['Jh'].norm().item()}\")\n",
    "        layerwise_jh[layer_name].append({\n",
    "            \"J\": operator.weight.norm().item(),\n",
    "            \"Jh\": operator.misc['Jh'].norm().item(),\n",
    "            \"bias\": operator.bias.norm().item()\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in mt.layer_names:\n",
    "    if layer in layerwise_jh and len(layerwise_jh[layer]) == 0:\n",
    "        layerwise_jh.pop(layer)\n",
    "\n",
    "with open(\"layer_sweep/layer_jh_info.json\", \"w\") as f:\n",
    "    json.dump(layerwise_jh, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"Jh\"\n",
    "\n",
    "info = {\n",
    "    layer: np.array([layerwise_jh[layer][i][key] for i in range(len(layerwise_jh[layer]))])\n",
    "    for layer in layerwise_jh.keys()\n",
    "}\n",
    "\n",
    "mean = [info[layer].mean() for layer in info.keys()]\n",
    "plt.plot(mean, color=\"blue\", linewidth=4)\n",
    "plt.xticks(range(0, len(mean), 2))\n",
    "plt.ylabel(f\"{key}_norm\")\n",
    "\n",
    "for i in range(len(set(model_knows) - set(icl_samples))):\n",
    "    arr = []\n",
    "    for layer in layerwise_jh.keys():\n",
    "        arr.append(layerwise_jh[layer][i][key])\n",
    "    plt.plot(arr, alpha=0.2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer sweep on mean ICL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "capital_cities_known = copy.deepcopy(capital_cities.__dict__)\n",
    "capital_cities_known[\"samples\"] = model_knows\n",
    "\n",
    "capital_cities_known = data.Relation(**capital_cities_known)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.random.choice(range(len(capital_cities_known.samples)), 2, replace=False)\n",
    "samples = [capital_cities_known.samples[i] for i in indices]\n",
    "\n",
    "capital_cities_subset = copy.deepcopy(capital_cities.__dict__)\n",
    "capital_cities_subset[\"samples\"] = samples\n",
    "capital_cities_subset = data.Relation(**capital_cities_subset)\n",
    "\n",
    "len(capital_cities_subset.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import JacobianIclMeanEstimator\n",
    "\n",
    "mean_estimator = JacobianIclMeanEstimator(\n",
    "    mt=mt,\n",
    "    h_layer=12,\n",
    ")\n",
    "\n",
    "operator = mean_estimator(capital_cities_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "operator(\"Chile\", k = 10).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "target = []\n",
    "\n",
    "for sample in tqdm(set(capital_cities_known.samples)):\n",
    "    cur_predictions = operator(sample.subject, k = 5).predictions\n",
    "    predictions.append([\n",
    "        p.token for p in cur_predictions\n",
    "    ])\n",
    "    target.append(sample.object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.metrics import recall\n",
    "\n",
    "recall(predictions, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez(\"layer_sweep/operator_weight.npz\", jacobian = operator.weight.detach().cpu().numpy(), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# j = np.load(\"layer_sweep/operator_weight.npz\", allow_pickle=True)[\"jacobian\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.dist(torch.tensor(j).to(device), operator.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_layer_wise_recall(capital_cities_subset, verbose = True, save_weights = True):\n",
    "\n",
    "    layer_wise_recall = {}\n",
    "\n",
    "    for h_layer in tqdm(range(0, 24)):\n",
    "        layer_name = mt.layer_name_format.format(h_layer)\n",
    "        mean_estimator = JacobianIclMeanEstimator(\n",
    "            mt=mt,\n",
    "            h_layer=h_layer,\n",
    "        )\n",
    "        operator = mean_estimator(capital_cities_subset)\n",
    "        if(save_weights):\n",
    "            np.savez(\n",
    "                f\"layer_sweep/weights_and_biases/{layer_name}.npz\", \n",
    "                jacobian = operator.weight.detach().cpu().numpy(),\n",
    "                bias = operator.bias.detach().cpu().numpy(), \n",
    "                allow_pickle=True\n",
    "            )\n",
    "\n",
    "        predictions = []\n",
    "        target = []\n",
    "\n",
    "        for sample in set(capital_cities_known.samples) - set(capital_cities_subset.samples):\n",
    "            cur_predictions = operator(sample.subject, k = 5).predictions\n",
    "            predictions.append([\n",
    "                p.token for p in cur_predictions\n",
    "            ])\n",
    "            target.append(sample.object)\n",
    "\n",
    "        layer_wise_recall[layer_name] = recall(predictions, target)\n",
    "        \n",
    "        if(verbose):\n",
    "            print(layer_name, layer_wise_recall[layer_name])\n",
    "    \n",
    "    return layer_wise_recall\n",
    "\n",
    "layer_wise_recall = get_layer_wise_recall(capital_cities_subset, verbose = True, save_weights = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"layer_sweep/layer_wise_recall.json\", \"w\") as f:\n",
    "    json.dump(layer_wise_recall, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_wise_recall_collection = {}\n",
    "number_of_runs = 10\n",
    "\n",
    "for run in tqdm(range(number_of_runs)):\n",
    "    indices = np.random.choice(range(len(capital_cities_known.samples)), 2, replace=False)\n",
    "    samples = [capital_cities_known.samples[i] for i in indices]\n",
    "\n",
    "    capital_cities_subset = copy.deepcopy(capital_cities.__dict__)\n",
    "    capital_cities_subset[\"samples\"] = samples\n",
    "    capital_cities_subset = data.Relation(**capital_cities_subset)\n",
    "\n",
    "    layer_wise_recall = get_layer_wise_recall(capital_cities_subset, verbose=False, save_weights=False)\n",
    "\n",
    "    for layer in layer_wise_recall.keys():\n",
    "        if(layer not in layer_wise_recall_collection):\n",
    "            layer_wise_recall_collection[layer] = []\n",
    "        layer_wise_recall_collection[layer].append(layer_wise_recall[layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"layer_sweep/layer_wise_recall_collection.json\", \"w\") as f:\n",
    "    json.dump(layer_wise_recall_collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_1 = np.array([\n",
    "    np.array(layer_wise_recall_collection[layer])[:, 0]\n",
    "    for layer in layer_wise_recall_collection.keys()\n",
    "])\n",
    "top_1.mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top_1 = [layer_wise_recall[layer][0] for layer in layer_wise_recall.keys()]\n",
    "# top_2 = [layer_wise_recall[layer][1] for layer in layer_wise_recall.keys()]\n",
    "# top_3 = [layer_wise_recall[layer][2] for layer in layer_wise_recall.keys()]\n",
    "\n",
    "top_1 = np.array([\n",
    "    np.array(layer_wise_recall_collection[layer])[:, 0]\n",
    "    for layer in layer_wise_recall_collection.keys()\n",
    "])\n",
    "\n",
    "top_2 = np.array([\n",
    "    np.array(layer_wise_recall_collection[layer])[:, 1]\n",
    "    for layer in layer_wise_recall_collection.keys()\n",
    "])\n",
    "\n",
    "top_3 = np.array([\n",
    "    np.array(layer_wise_recall_collection[layer])[:, 2]\n",
    "    for layer in layer_wise_recall_collection.keys()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(top_1.mean(axis=1), color=\"green\", linewidth=3, label=\"recall@1\")\n",
    "plt.plot(top_2.mean(axis=1), color=\"blue\", linewidth=2, label=\"recall@2\")\n",
    "plt.plot(top_3.mean(axis=1), color=\"red\", linewidth=1, label=\"recall@3\")\n",
    "\n",
    "plt.fill_between(\n",
    "    range(len(layer_wise_recall_collection.keys())),\n",
    "    top_1.min(axis=1), top_1.max(axis=1),\n",
    "    color=\"green\", alpha=0.1\n",
    ")\n",
    "\n",
    "plt.xticks(range(0, len(top_1), 2))\n",
    "plt.xlabel(\"layer\")\n",
    "plt.ylabel(\"recall\")\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils.misc import visualize_matrix\n",
    "\n",
    "for h_layer in range(0, 24):\n",
    "    layer_name = mt.layer_name_format.format(h_layer)\n",
    "    j = np.load(f\"layer_sweep/weights_and_biases/{layer_name}.npz\", allow_pickle=True)[\"jacobian\"]\n",
    "    j = torch.tensor(j).to(device)\n",
    "    print(layer_name, j.shape)\n",
    "    visualize_matrix(j, title = layer_name, save_path=f\"layer_sweep/Jacobian_plots/{layer_name}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
