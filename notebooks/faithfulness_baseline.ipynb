{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src import models, data\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\"\n",
    "mt = models.load_model(\"gptj\", device=device)\n",
    "print(\n",
    "    f\"dtype: {mt.model.dtype}, device: {mt.model.device}, memory: {mt.model.get_memory_footprint()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.lens import interpret_logits, logit_lens\n",
    "from src.functional import untuple\n",
    "\n",
    "prompt = \"Prudential Tower is located in the city of\"\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True).to(mt.model.device)\n",
    "\n",
    "import baukit\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    mt.model,\n",
    "    models.determine_layer_paths(mt)\n",
    ") as traces:\n",
    "    output = mt.model(**tokenized)\n",
    "    \n",
    "interpret_logits(mt, output.logits[0][-1], get_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interested_words = [\" Seattle\", \" Paris\", \" Dhaka\"]\n",
    "int_tokenized = mt.tokenizer(interested_words, return_tensors=\"pt\", padding=True).to(\n",
    "    mt.model.device\n",
    ")\n",
    "int_tokenized.input_ids\n",
    "\n",
    "z = untuple(traces[models.determine_layer_paths(mt)[-1]].output)[0][-1]\n",
    "print(z.shape)\n",
    "\n",
    "logit_lens(mt, z, [t[0] for t in int_tokenized.input_ids], get_proba=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $F(\\mathbf{h_{s}}) = \\mathbf{h_{s}}$, set $W_{r} = I$ and $bias = \\mathbf{0}$, basically logit lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import LinearRelationOperator\n",
    "\n",
    "logit_lens_operator = LinearRelationOperator(\n",
    "    mt = mt, \n",
    "    h_layer = -1,\n",
    "    weight = None, bias = None, # basically logit lens if both weight and bias set to None\n",
    "    prompt_template=\"{} is located in the city of\",\n",
    "    z_layer = -1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_lens_operator(\n",
    "    subject = \"The Space Needle\",\n",
    "    k = 10,\n",
    "    h = z\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembedding = baukit.nethook.get_module(mt.model, \"lm_head\")\n",
    "unembedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \" Chicago\"\n",
    "emb_subject = unembedding.weight[mt.tokenizer(subject).input_ids[0]]\n",
    "logit_lens_operator(\n",
    "    subject = \"Whatever\",\n",
    "    k = 10,\n",
    "    h = emb_subject\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import load_dataset\n",
    "dataset = load_dataset()\n",
    "cur_relation = [\n",
    "    d for d in dataset if d.name == \"country capital city\"\n",
    "][0]\n",
    "train, test = cur_relation.split(size = 10)\n",
    "len(train.samples), len(test.samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICL-Mean, our flagship method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import JacobianIclMeanEstimator\n",
    "\n",
    "mean_estimator = JacobianIclMeanEstimator(\n",
    "    mt = mt,\n",
    "    h_layer = 12,\n",
    "    beta= 0.5\n",
    ")\n",
    "\n",
    "icl_mean = mean_estimator(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned Linear Model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import LearnedLinearEstimatorBaseline\n",
    "    \n",
    "learned_estimator = LearnedLinearEstimatorBaseline(\n",
    "    mt=mt,\n",
    "    h_layer=15,\n",
    ")\n",
    "\n",
    "learned_operator = learned_estimator(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset Model (a simpler version of the `corner` approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import OffsetEstimatorBaseline\n",
    "    \n",
    "offset_estimator = OffsetEstimatorBaseline(\n",
    "    mt=mt,\n",
    "    h_layer=15,\n",
    "    # scaling_factor=70\n",
    ")\n",
    "\n",
    "offset_operator = offset_estimator(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject = \"France\"\n",
    "\n",
    "print(learned_operator(subject).predictions)\n",
    "print(icl_mean(subject).predictions)\n",
    "print(offset_operator(subject).predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sample_pair_with_different_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list((i for i in range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
