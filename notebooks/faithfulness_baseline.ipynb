{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from src import models, data\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype: torch.float16, device: cuda:0, memory: 12219206136\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:0\"\n",
    "mt = models.load_model(\"gptj\", device=device)\n",
    "print(\n",
    "    f\"dtype: {mt.model.dtype}, device: {mt.model.device}, memory: {mt.model.get_memory_footprint()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' Chicago', 0.51),\n",
       " (' Newark', 0.174),\n",
       " (' Boston', 0.069),\n",
       " (' San', 0.031),\n",
       " (' Houston', 0.014),\n",
       " (' Minneapolis', 0.011),\n",
       " (' Jersey', 0.011),\n",
       " (' London', 0.011),\n",
       " (' Detroit', 0.01),\n",
       " (' Baltimore', 0.009)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.lens import interpret_logits, logit_lens\n",
    "from src.functional import untuple\n",
    "\n",
    "prompt = \"Prudential Tower is located in the city of\"\n",
    "tokenized = mt.tokenizer(prompt, return_tensors=\"pt\", padding=True).to(mt.model.device)\n",
    "\n",
    "import baukit\n",
    "\n",
    "with baukit.TraceDict(\n",
    "    mt.model,\n",
    "    models.determine_layer_paths(mt)\n",
    ") as traces:\n",
    "    output = mt.model(**tokenized)\n",
    "    \n",
    "interpret_logits(mt, output.logits[0][-1], get_proba=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4096])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([(' Chicago', 0.514),\n",
       "  (' Newark', 0.172),\n",
       "  (' Boston', 0.068),\n",
       "  (' San', 0.031),\n",
       "  (' Houston', 0.014),\n",
       "  (' Minneapolis', 0.011),\n",
       "  (' Jersey', 0.011),\n",
       "  (' London', 0.011),\n",
       "  (' Detroit', 0.01),\n",
       "  (' Baltimore', 0.009)],\n",
       " {tensor(7312, device='cuda:0'): (0.0017547607421875, ' Seattle'),\n",
       "  tensor(6342, device='cuda:0'): (3.3974647521972656e-06, ' Paris'),\n",
       "  tensor(20529, device='cuda:0'): (9.1552734375e-05, ' Dh')})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interested_words = [\" Seattle\", \" Paris\", \" Dhaka\"]\n",
    "int_tokenized = mt.tokenizer(interested_words, return_tensors=\"pt\", padding=True).to(\n",
    "    mt.model.device\n",
    ")\n",
    "int_tokenized.input_ids\n",
    "\n",
    "z = untuple(traces[models.determine_layer_paths(mt)[-1]].output)[0][-1]\n",
    "print(z.shape)\n",
    "\n",
    "logit_lens(mt, z, [t[0] for t in int_tokenized.input_ids], get_proba=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $F(\\mathbf{h_{s}}) = \\mathbf{h_{s}}$, set $W_{r} = I$ and $bias = \\mathbf{0}$, basically logit lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.operators import LinearRelationOperator\n",
    "\n",
    "logit_lens_operator = LinearRelationOperator(\n",
    "    mt = mt, \n",
    "    h_layer = -1,\n",
    "    weight = None, bias = None, # basically logit lens if both weight and bias set to None\n",
    "    prompt_template=\"{} is located in the city of\",\n",
    "    z_layer = -1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRelationOutput(predictions=[PredictedToken(token=' Chicago', prob=0.5139787793159485), PredictedToken(token=' Newark', prob=0.17216132581233978), PredictedToken(token=' Boston', prob=0.06848104298114777), PredictedToken(token=' San', prob=0.030866824090480804), PredictedToken(token=' Houston', prob=0.013804498128592968), PredictedToken(token=' Minneapolis', prob=0.011266903951764107), PredictedToken(token=' Jersey', prob=0.011092226952314377), PredictedToken(token=' London', prob=0.010501908138394356), PredictedToken(token=' Detroit', prob=0.010178797878324986), PredictedToken(token=' Baltimore', prob=0.00850470457226038)], h=tensor([-1.4648,  0.7959, -0.9663,  ..., -0.6025,  0.8594, -4.9844],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>), z=tensor([-1.4648,  0.7959, -0.9663,  ..., -0.6025,  0.8594, -4.9844],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit_lens_operator(\n",
    "    subject = \"The Space Needle\",\n",
    "    k = 10,\n",
    "    h = z\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50400, 4096])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unembedding = baukit.nethook.get_module(mt.model, \"lm_head\")\n",
    "unembedding.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRelationOutput(predictions=[PredictedToken(token=' Chicago', prob=1.0), PredictedToken(token='Chicago', prob=6.665581192860808e-23), PredictedToken(token=' Detroit', prob=3.3952676397964373e-28), PredictedToken(token=' Illinois', prob=2.333531109663677e-28), PredictedToken(token=' Boston', prob=5.542621749889874e-29), PredictedToken(token=' Milwaukee', prob=4.0150617628607155e-30), PredictedToken(token=' Philadelphia', prob=3.1269332749387515e-30), PredictedToken(token=' Seattle', prob=6.157297243929202e-31), PredictedToken(token=' Toronto', prob=3.096083083978257e-31), PredictedToken(token=' Atlanta', prob=1.3738785357297722e-31)], h=tensor([-0.0243, -0.0335, -0.0092,  ..., -0.0075,  0.0104,  0.0171],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>), z=tensor([-0.0243, -0.0335, -0.0092,  ..., -0.0075,  0.0104,  0.0171],\n",
       "       device='cuda:0', dtype=torch.float16, grad_fn=<SelectBackward0>))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subject = \" Chicago\"\n",
    "emb_subject = unembedding.weight[mt.tokenizer(subject).input_ids[0]]\n",
    "logit_lens_operator(\n",
    "    subject = \"Whatever\",\n",
    "    k = 10,\n",
    "    h = emb_subject\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.data import load_dataset\n",
    "dataset = load_dataset()\n",
    "cur_relation = [\n",
    "    d for d in dataset if d.name == \"country capital city\"\n",
    "][0]\n",
    "train, test = cur_relation.split(size = 10)\n",
    "len(train.samples), len(test.samples)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ICL-Mean, our flagship method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "relation has > 1 prompt_templates, will use first (The capital city of {} is)\n"
     ]
    }
   ],
   "source": [
    "from src.operators import JacobianIclMeanEstimator\n",
    "\n",
    "mean_estimator = JacobianIclMeanEstimator(\n",
    "    mt = mt,\n",
    "    h_layer = 12,\n",
    "    beta= 0.5\n",
    ")\n",
    "\n",
    "icl_mean = mean_estimator(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learned Linear Model baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "relation has > 1 prompt_templates, will use first (The capital city of {} is)\n"
     ]
    }
   ],
   "source": [
    "from src.operators import LearnedLinearEstimatorBaseline\n",
    "    \n",
    "learned_estimator = LearnedLinearEstimatorBaseline(\n",
    "    mt=mt,\n",
    "    h_layer=15,\n",
    ")\n",
    "\n",
    "learned_operator = learned_estimator(train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offset Model (a simpler version of the `corner` approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "relation has > 1 prompt_templates, will use first (The capital city of {} is)\n"
     ]
    }
   ],
   "source": [
    "from src.operators import OffsetEstimatorBaseline\n",
    "    \n",
    "offset_estimator = OffsetEstimatorBaseline(\n",
    "    mt=mt,\n",
    "    h_layer=15,\n",
    "    # scaling_factor=70\n",
    ")\n",
    "\n",
    "offset_operator = offset_estimator(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PredictedToken(token=' Madrid', prob=0.050866398960351944), PredictedToken(token=' \\\\', prob=0.03183137997984886), PredictedToken(token='\\\\', prob=0.03013734519481659), PredictedToken(token=' Sacramento', prob=0.018859468400478363), PredictedToken(token=' incl', prob=0.015881264582276344)]\n",
      "[PredictedToken(token=' Paris', prob=0.9226482510566711), PredictedToken(token=' French', prob=0.04248381406068802), PredictedToken(token=' France', prob=0.014682012610137463), PredictedToken(token=' Franc', prob=0.008497295901179314), PredictedToken(token=' Buenos', prob=0.0010470723500475287)]\n",
      "[PredictedToken(token=' Paris', prob=0.9273013472557068), PredictedToken(token=' Moscow', prob=0.03173050656914711), PredictedToken(token=' Berlin', prob=0.012425845488905907), PredictedToken(token=' London', prob=0.007304777856916189), PredictedToken(token=' Tokyo', prob=0.007080032490193844)]\n"
     ]
    }
   ],
   "source": [
    "subject = \"France\"\n",
    "\n",
    "print(learned_operator(subject).predictions)\n",
    "print(icl_mean(subject).predictions)\n",
    "print(offset_operator(subject).predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RelationSample(subject='Canada', object='Ottawa'),\n",
       " RelationSample(subject='Colombia', object='Bogot\\\\u00e1'))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.sample_pair_with_different_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list((i for i in range(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
