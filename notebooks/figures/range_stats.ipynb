{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from src import data\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from src.metrics import AggregateMetric\n",
    "import logging\n",
    "\n",
    "from src.utils import logging_utils\n",
    "from src.models import load_model\n",
    "\n",
    "\n",
    "# logging_utils.configure(level=logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats = {}\n",
    "\n",
    "# dataset = data.load_dataset()\n",
    "# for relation in dataset:\n",
    "#     stats[relation.name] = {\n",
    "#         \"name\": relation.name,\n",
    "#         \"category\": relation.properties.relation_type,\n",
    "#         \"num_samples\": len(relation.samples),\n",
    "#         \"|range|\": len(set(relation.range))\n",
    "#     }\n",
    "\n",
    "# with open(\"stats/range_stats.json\", \"w\") as f:\n",
    "#     json.dump(stats, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0ef885d15824dab966580366b5403c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/41 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"llama\"\n",
    "\n",
    "mt = load_model(model_name, fp16=model_name != \"gpt2-xl\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'woman'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok_id = mt.tokenizer(\" 1996\").input_ids[2]\n",
    "mt.tokenizer.decode(tok_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" 1996\".isnumeric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stats/range_stats.json\", \"r\") as f:\n",
    "    stats = json.load(f)\n",
    "\n",
    "dataset = data.load_dataset()\n",
    "prefix = \" \" if model_name != \"llama\" else \"\"\n",
    "\n",
    "for relation in dataset:\n",
    "    if relation.name not in stats:\n",
    "        continue\n",
    "    first_tokens = []\n",
    "    for obj in relation.range:\n",
    "        idx = 0\n",
    "        if model_name == \"llama\":\n",
    "            idx = 2 if obj.isnumeric() else 1\n",
    "        tok_id = mt.tokenizer(prefix + obj).input_ids[idx]\n",
    "        # print(idx, tok_id, f\"`{obj}` | `{mt.tokenizer.decode(tok_id)}`\")\n",
    "        first_tokens.append(mt.tokenizer.decode(tok_id))\n",
    "    stats[relation.name][model_name] = len(set(first_tokens))\n",
    "\n",
    "with open(\"stats/range_stats.json\", \"w\") as f:\n",
    "    json.dump(stats, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"stats/range_stats.json\", \"r\") as f:\n",
    "    stats = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lllll}\n",
      "Relation & |range| & GPT-J & GPT2-xl & LLaMa-13B \\\\\n",
      "adjective antonym & $95$ & $95$ & $95$ & $94$ \\\\\n",
      "adjective comparative & $57$ & $57$ & $57$ & $53$ \\\\\n",
      "adjective superlative & $79$ & $77$ & $77$ & $78$ \\\\\n",
      "city in country & $21$ & $20$ & $20$ & $20$ \\\\\n",
      "company CEO & $287$ & $208$ & $208$ & $194$ \\\\\n",
      "company hq & $163$ & $163$ & $163$ & $152$ \\\\\n",
      "country currency & $23$ & $23$ & $23$ & $21$ \\\\\n",
      "landmark in country & $91$ & $91$ & $91$ & $89$ \\\\\n",
      "person father & $968$ & $400$ & $400$ & $377$ \\\\\n",
      "person lead singer of band & $21$ & $18$ & $18$ & $18$ \\\\\n",
      "person mother & $962$ & $380$ & $380$ & $307$ \\\\\n",
      "person occupation & $31$ & $31$ & $31$ & $29$ \\\\\n",
      "person university & $69$ & $37$ & $37$ & $35$ \\\\\n",
      "pokemon evolution & $44$ & $40$ & $40$ & $36$ \\\\\n",
      "president birth year & $15$ & $9$ & $9$ & $1$ \\\\\n",
      "president election year & $18$ & $14$ & $14$ & $2$ \\\\\n",
      "product by company & $30$ & $30$ & $30$ & $26$ \\\\\n",
      "star constellation name & $31$ & $29$ & $29$ & $27$ \\\\\n",
      "superhero archnemesis & $90$ & $76$ & $76$ & $73$ \\\\\n",
      "superhero person & $100$ & $89$ & $89$ & $84$ \\\\\n",
      "task done by tool & $51$ & $50$ & $50$ & $46$ \\\\\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "relation_stats = [\n",
    "    stats[relation] \n",
    "    for relation in stats \n",
    "]\n",
    "\n",
    "relation_stats = sorted(\n",
    "    relation_stats, key=lambda x: x[\"name\"],\n",
    ")\n",
    "\n",
    "table = []\n",
    "\n",
    "def check_range_mismatch(relation_stat):\n",
    "    for unique_first_tokens in [relation_stat[\"gptj\"], relation_stat[\"gpt2-xl\"], relation_stat[\"llama\"]]:\n",
    "        if unique_first_tokens != relation_stat[\"|range|\"]:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "for relation in relation_stats:\n",
    "    if not check_range_mismatch(relation):\n",
    "        table.append({\n",
    "            \"Relation\": f'{relation[\"name\"]}',\n",
    "            \"|range|\": f'${relation[\"|range|\"]}$',\n",
    "            \"GPT-J\": f'${relation[\"gptj\"]}$',\n",
    "            \"GPT2-xl\": f'${relation[\"gpt2-xl\"]}$',\n",
    "            \"LLaMa-13B\": f'${relation[\"llama\"]}$',\n",
    "        })\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(table)\n",
    "print(df.style.hide(axis = \"index\").to_latex())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[PredictedToken(token='Paris', prob=0.6106753349304199),\n",
       "  PredictedToken(token='the', prob=0.18335798382759094),\n",
       "  PredictedToken(token='France', prob=0.031124738976359367),\n",
       "  PredictedToken(token='a', prob=0.014702285639941692),\n",
       "  PredictedToken(token='', prob=0.008847991935908794)]]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.functional import predict_next_token\n",
    "\n",
    "predict_next_token(\n",
    "    mt = mt, \n",
    "    prompt = \"Eiffel Tower is located in\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relations",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
